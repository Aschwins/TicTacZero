{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from tictaczero.board import Board, EMPTY, CROSS, CIRCLE\n",
    "from tictaczero.player import BasePlayer, RandomPlayer, SmartPlayer, BrainPlayer\n",
    "from tictaczero.games import play_a_game\n",
    "\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_x_brainy_games(x=100):\n",
    "    \"\"\"\n",
    "    Plays x games and returns both (hopefully) smarter players.\n",
    "    \"\"\"\n",
    "    player1 = BrainPlayer(side=CROSS)\n",
    "    player2 = BrainPlayer(side=CIRCLE)\n",
    "    \n",
    "    for i in range(x):\n",
    "        result = play_a_game(player1, player2, print_result=False)\n",
    "        player1.memorize(result)\n",
    "        player2.memorize(result)\n",
    "        \n",
    "    return player1, player2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.9 s ± 1.63 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "rBplayer1, rBplayer2 = play_x_brainy_games(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 10)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rBplayer1.memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_brainy_games(BPlayer1, BPlayer2, x = 100):\n",
    "    player1 = BPlayer1\n",
    "    player2 = BPlayer2\n",
    "    \n",
    "    play_a_game(player1, player2):\n",
    "        \n",
    "    \"\"\"\n",
    "    Playes x games and returns both (hopefully) smarter players/\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return player1, player2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-167-8757c2b9fdcb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-167-8757c2b9fdcb>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for i in range(x):\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def play_brainy_games(BPlayer1, BPlayer2, x = 100):\n",
    "    states = np.zeros(shape(1, 10), dtype = np.int32)\n",
    "    for i in range(x):\n",
    "        board_history = play_a_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_x_games(Player1, Player2, x=100):\n",
    "    states = np.zeros(shape=(1, 10), dtype=np.int32)\n",
    "    for i in range(x):\n",
    "        board_history = play_a_game(Player1, Player2)\n",
    "        \n",
    "        states = np.concatenate((states, board_history), axis = 0)\n",
    "        \n",
    "    return states\n",
    "\n",
    "df = play_x_games(SmartPlayer, SmartPlayer, x=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Board(3)\n",
    "\n",
    "squares, board_states = board.next_board_states(CROSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = BrainPlayer(side=CROSS, max_memory=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.memorize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.max_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31411847, 0.24697386, 0.43890762]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.brain.predict(np.array([[0, 1, -1, 0, 0, 0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  1, -1,  0],\n",
       "       [ 0,  0,  0, ...,  1, -1,  0],\n",
       "       [ 0,  0,  0, ...,  1, -1,  0],\n",
       "       ...,\n",
       "       [-1, -1,  1, ...,  0,  1,  1],\n",
       "       [-1, -1,  1, ...,  0,  1,  1],\n",
       "       [-1, -1,  1, ...,  0,  1,  1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1,  1,  1,  0,  0,  0,  0,  1,  1],\n",
       "       [-1, -1,  1,  1,  0,  0, -1,  0,  1,  1],\n",
       "       [-1, -1,  1,  1,  0,  1, -1,  0,  1,  1]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[-3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  1,  0,  0],\n",
       "       ...,\n",
       "       [-1, -1,  1, ...,  0,  1,  1],\n",
       "       [-1, -1,  1, ...,  0,  1,  1],\n",
       "       [-1, -1,  1, ...,  0,  1,  1]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a state.\n",
    "\n",
    "We need an agent (player)\n",
    "\n",
    "Agent can make an action\n",
    "\n",
    "Agent gets a reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0,  0,  0, -1,  0,  0,  0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = Board(3)\n",
    "\n",
    "board.move(1, CROSS)\n",
    "board.move(5, CIRCLE)\n",
    "\n",
    "np.array([board.state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35162076, 0.30168402, 0.34669527], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.brain.predict(np.array([board.state]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network architecture:\n",
    "\n",
    "Input layer:\n",
    "$$B + S = 9+1 = 10 \\text{ Nodes}$$\n",
    "\n",
    "Where $B$ is the board state and $S$ is the side. \n",
    "\n",
    "Output layer:\n",
    "$$B + S = 9+1 = 10 \\text{ Nodes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTION 1\n",
    "\n",
    "Have the neural network predict the move.\n",
    "\n",
    "# OPTION 2 \n",
    "\n",
    "Have the neural network predict the outcome of the game. And let a Q-learning agent decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTION 2 - Network predicts outcome.\n",
    "\n",
    "\n",
    "## The Network\n",
    "In this section we're going to build a neural network which predicts the outcome of a game of tic tac toe give a certain board state. First we'll have to generate enough board states with outcomes.\n",
    "\n",
    "In total there are three outcomes:\n",
    "\n",
    "1 - CROSS WINS\n",
    "\n",
    "-1 - CIRCLE WINS\n",
    "\n",
    "0 - DRAW\n",
    "\n",
    "So the output layer consists of three nodes. The input layer consists of the board state. We don't give the turn because CROSS always starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(28, input_shape = [9], activation = 'relu'),\n",
    "    keras.layers.Dense(28, activation = 'relu'),\n",
    "    keras.layers.Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are only $3^9=19683$ different possible tic-tac-toe positions. With mirror or rotation permutation even less. Let's try to generate 10.000 games and save each result of the game and put in the following dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:,:-1]\n",
    "y = df[:, -1]\n",
    "\n",
    "\n",
    "cut_off = 0.7\n",
    "\n",
    "X_train = X[:int(cut_off*len(X))]\n",
    "X_test = X[int(cut_off*len(X)):]\n",
    "y_train = y[:int(cut_off*len(X))]\n",
    "y_test = y[int(cut_off*len(X)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tf = tf.convert_to_tensor(X_train, np.float32)\n",
    "ytrain_tf = tf.convert_to_tensor(y_train, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4942 samples\n",
      "Epoch 1/20\n",
      "4942/4942 [==============================] - 1s 105us/sample - loss: 0.8843 - accuracy: 0.6081\n",
      "Epoch 2/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.7266 - accuracy: 0.7094\n",
      "Epoch 3/20\n",
      "4942/4942 [==============================] - 0s 28us/sample - loss: 0.6886 - accuracy: 0.7169\n",
      "Epoch 4/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.6606 - accuracy: 0.7214\n",
      "Epoch 5/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.6371 - accuracy: 0.7303\n",
      "Epoch 6/20\n",
      "4942/4942 [==============================] - 0s 26us/sample - loss: 0.6214 - accuracy: 0.7376\n",
      "Epoch 7/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.6081 - accuracy: 0.7406\n",
      "Epoch 8/20\n",
      "4942/4942 [==============================] - 0s 26us/sample - loss: 0.5953 - accuracy: 0.7481\n",
      "Epoch 9/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.5852 - accuracy: 0.7507\n",
      "Epoch 10/20\n",
      "4942/4942 [==============================] - 0s 26us/sample - loss: 0.5765 - accuracy: 0.7523\n",
      "Epoch 11/20\n",
      "4942/4942 [==============================] - 0s 25us/sample - loss: 0.5683 - accuracy: 0.7582\n",
      "Epoch 12/20\n",
      "4942/4942 [==============================] - 0s 28us/sample - loss: 0.5596 - accuracy: 0.7637\n",
      "Epoch 13/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.5529 - accuracy: 0.7675\n",
      "Epoch 14/20\n",
      "4942/4942 [==============================] - 0s 28us/sample - loss: 0.5451 - accuracy: 0.7685\n",
      "Epoch 15/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.5383 - accuracy: 0.7746\n",
      "Epoch 16/20\n",
      "4942/4942 [==============================] - 0s 25us/sample - loss: 0.5318 - accuracy: 0.7786\n",
      "Epoch 17/20\n",
      "4942/4942 [==============================] - 0s 25us/sample - loss: 0.5255 - accuracy: 0.7774\n",
      "Epoch 18/20\n",
      "4942/4942 [==============================] - 0s 26us/sample - loss: 0.5199 - accuracy: 0.7853\n",
      "Epoch 19/20\n",
      "4942/4942 [==============================] - 0s 28us/sample - loss: 0.5141 - accuracy: 0.7902\n",
      "Epoch 20/20\n",
      "4942/4942 [==============================] - 0s 27us/sample - loss: 0.5084 - accuracy: 0.7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x143178d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_tf, ytrain_tf, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(tf.convert_to_tensor(X_test, np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03995128, 0.7037237 , 0.25632495]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tf.convert_to_tensor(np.array([[0,0,0,0,0,0,0,0,0]]), np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8495394e-04, 9.6335566e-01, 3.6459364e-02]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[2,2,0,0,1,0,0,1,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 291, 1: 3315, 2: 1336})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.array([[0,0,0,0,0,0,0,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 8678, 2: 1420, 3: 250})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 3114, 1: 6584, 3: 650})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"y_pred\": y_pred, \"y_test\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = results.assign(wrong = lambda d: d[\"y_pred\"] != d[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2908774642442984"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(results['wrong'])/len(results['wrong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10343</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10344</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10345</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10346</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10347</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10348 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred  y_test  wrong\n",
       "0           1       2   True\n",
       "1           1       2   True\n",
       "2           1       2   True\n",
       "3           2       2  False\n",
       "4           2       2  False\n",
       "...       ...     ...    ...\n",
       "10343       1       1  False\n",
       "10344       1       1  False\n",
       "10345       1       1  False\n",
       "10346       1       1  False\n",
       "10347       3       1   True\n",
       "\n",
       "[10348 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3\n",
    "\n",
    "class Board2:\n",
    "    def __init__(self, p1, p2):\n",
    "            self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "            self.p1 = p1\n",
    "            self.p2 = p2\n",
    "            self.isEnd = False\n",
    "            self.boardHash = None\n",
    "            # init p1 plays first\n",
    "            self.playerSymbol = 1\n",
    "            \n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "    \n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))\n",
    "        return positions\n",
    "    \n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        \n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "        \n",
    "    def winner(self):\n",
    "        # row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "            \n",
    "        # col\n",
    "        for j in range(BOARD_COLS):\n",
    "            if sum(self.board[:, j]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, j]) == -3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            \n",
    "        # diagonal\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        # tie\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "        # not done\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        # backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "            \n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "                \n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions,\n",
    "                                                 self.board,\n",
    "                                                 self.playerSymbol)\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                \n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions,\n",
    "                                                     self.board,\n",
    "                                                     self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "                    \n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "                        \n",
    "    # play against human\n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # take action and upate board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            # check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "\n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}\n",
    "        \n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "            \n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = current_board.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                #print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "                    \n",
    "        # print(f\"{self.name} takes action {action}\")\n",
    "        return action\n",
    "    \n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr * [self.decay_gamma * reward - self.states_value[st]]\n",
    "            reward = self.states_value[st]\n",
    "            \n",
    "    # accept a state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "            \n",
    "    def savePolicy(self):\n",
    "        fw = open('policy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "        \n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.state_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row: \"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "            \n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player('Player1')\n",
    "p2 = Player('Player2')\n",
    "\n",
    "board = Board2(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Board2 at 0x122229d10>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
